{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순차 데이터\n",
    "\n",
    "순차데이터: 텍스트나 시계열 데이터와 같이 순서에 의미가 있는 데이터\n",
    "\n",
    "이전에 입력한 데이터를 기억하는 신경망 = 순환 신경망\n",
    "데이터의 흐름이 앞으로만 전달되는 신경망 = 피드포워드 신경망"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순환 신경망\n",
    "\n",
    "recurrent neural network, RNN\n",
    "\n",
    "출력을 다음 입력에 사용\n",
    "\n",
    "time step  \n",
    "cell  \n",
    "hidden state  \n",
    "\n",
    "activation으로 tanh를 주로 사용  \n",
    "ReLU는 발산할 수 있기 때문에 nomalizing이 필요하고, sigmoid보다는 tanh가 기울기가 0~1이라 소실이 덜하기 때문에 tanh를 사용\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
